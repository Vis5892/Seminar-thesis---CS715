{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LaUZ2aouiKn9y0ak1USJMQNahXJB7PEr",
      "authorship_tag": "ABX9TyOJfvcEU4UmxnshZUCA/ha0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vis5892/Seminar-thesis---CS715/blob/main/Closed_IE_GPT_3_5_turbo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# open the JSON file in read mode\n",
        "# with open('/content/drive/MyDrive/Zero_shot_task_dict.json', 'r') as f:\n",
        "# with open('/content/drive/MyDrive/Zero_shot_role1_task_dict.json', 'r') as f:\n",
        "# with open('/content/drive/MyDrive/Zero_shot_role2_task_dict.json', 'r') as f:\n",
        "with open('/content/drive/MyDrive/Zero_shot_context_task_dict.json', 'r') as f:\n",
        "    # load the JSON data from the file and convert it into a dictionary\n",
        "    task_dict = json.load(f)\n",
        "\n",
        "# print the dictionary\n",
        "print(task_dict)"
      ],
      "metadata": {
        "id": "3CmE_qp0E5yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Initializing LLMs***"
      ],
      "metadata": {
        "id": "xj1QCPTl6GBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai"
      ],
      "metadata": {
        "id": "rsi1Yi-ucLLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "WmuvzzlUbZC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "veb7lyYkbY_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "k4sOeTkBbYwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from langchain.callbacks import get_openai_callback"
      ],
      "metadata": {
        "id": "U5Sk9g_xcLgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = getpass()"
      ],
      "metadata": {
        "id": "F7atCoxQcLjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Function to get tokens used for a call***"
      ],
      "metadata": {
        "id": "2HYW4G8rsWhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(chain, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        result = chain.run(query)\n",
        "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "7oxPINHzcLrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Initializing and running LLM chain to get predictions***"
      ],
      "metadata": {
        "id": "o1S2geZNsdjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LangChain PromptTemplate\n",
        "from langchain import PromptTemplate, LLMChain, OpenAI\n",
        "\n",
        "template = \"\"\"{task_prefix}{input_string}\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "        template=template,\n",
        "        input_variables=['task_prefix', 'input_string']\n",
        ")\n",
        "\n",
        "gpt_3_turbo = OpenAI(model_name='gpt-3.5-turbo', openai_api_key = OPENAI_API_KEY)\n",
        "# gpt_3 = OpenAI(model_name='text-davinci-003', openai_api_key = OPENAI_API_KEY)\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=gpt_3_turbo\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "targets = [example['target_scores'] for example in task_dict['examples']]\n",
        "with get_openai_callback() as cb:\n",
        "    preds = [llm_chain.run({'task_prefix': task_dict['task_prefix'], 'input_string': example['input']}) for example in task_dict['examples']]\n",
        "    print(f'Spent a total of {cb.total_tokens} tokens')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJomHkp0t2OE",
        "outputId": "8661f25b-b0aa-4ae5-daf1-4eafff3d78e4"
      },
      "execution_count": 586,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 8596 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Examples for One-shot prompts**"
      ],
      "metadata": {
        "id": "gyaQ5GxpjOoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "   {\n",
        "        \"product_title\": \"Remanufactured IBM ThinkPad T23 1.13 GHz Pentium III Notebook PC with 30 GB \\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Pentium\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# examples = [\n",
        "#     {\n",
        "#          \"product_title\": \"Remanufactured IBM ThinkPad T23 1.13 GHz Pentium III Notebook PC with 30 GB \\n Requested Attribute: Processor Brand\",\n",
        "#          \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Processor Brand', which is Pentium. So the answer is Pentium\"\n",
        "#      }\n",
        "# ]"
      ],
      "metadata": {
        "id": "e4u-9FhhjFum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Examples for 3-shot prompts**"
      ],
      "metadata": {
        "id": "R-ItLGDmjXMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# examples = [\n",
        "#    {\n",
        "#         \"product_title\": \"Sony KV-20FV12 20 Trinitron Wega Flat-Screen TV \\n Requested Attribute: Screen Form\",\n",
        "#         \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Screen Form', which is Flat. So the answer Flat.\"\n",
        "#     }, {\n",
        "#         \"product_title\": \"Eastwood Warren Ellis Tenor - Cherry Red\\n Requested Attribute: Ukulele Type\",\n",
        "#         \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Ukulele Type', which is Tenor. So the answer Tenor.\"\n",
        "#     }, {\n",
        "#         \"product_title\": \"Sharp LC-20E1U 20-Inch AQUOS LCD Flat-Panel TV, Silver\\n Requested Attribute: Display Type\",\n",
        "#         \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Display Type', which is LCD. So the answer LCD.\"\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "examples = [\n",
        "   {\n",
        "        \"product_title\": \"Sony KV-20FV12 20 Trinitron Wega Flat-Screen TV \\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    }, {\n",
        "        \"product_title\": \"Eastwood Warren Ellis Tenor - Cherry Red\\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Tenor\"\n",
        "    }, {\n",
        "        \"product_title\": \"Sharp LC-20E1U 20-Inch AQUOS LCD Flat-Panel TV, Silver\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"LCD\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "d3kvDO-IjF1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Examples for 6-shot Prompt**"
      ],
      "metadata": {
        "id": "QChF599ZjloJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# examples = [\n",
        "#    {\n",
        "#         \"product_title\": \"Sony KV-20FV12 20 Trinitron Wega Flat-Screen TV \\n Requested Attribute: Screen Form\",\n",
        "#         \"attribute\": \"Flat\"\n",
        "#     }, {\n",
        "#         \"product_title\": \"Fender Villager 12-String Acoustic-Electric Guitar \\n Requested Attribute: Guitar Type\",\n",
        "#         \"attribute\": \"Acoustic-Electric\"\n",
        "#     }, {\n",
        "#         \"product_title\": \"Remanufactured IBM ThinkPad T23 1.13 GHz Pentium III Notebook PC with 30 GB \\n Requested Attribute: Processor Brand\",\n",
        "#         \"attribute\": \"Pentium\"\n",
        "#     }, {\n",
        "#         \"product_title\": \"Taylor Guitars NS72-CE Grand Concert Acoustic Electric Classical Guitar \\n Requested Attribute: Ukulele Type\",\n",
        "#         \"attribute\": \"Concert\"\n",
        "#     }, {\n",
        "#         \"product_title\": \"RCA LCDX3022W 30 LCD Flat Panel HD-Compatible TV \\n Requested Attribute: Display Type\",\n",
        "#         \"attribute\": \"LCD\"\n",
        "#     },{\n",
        "#         \"product_title\": \" HP Pavilion ZT1195 Notebook (1.5GHz Intel Pentium IIII, 512MB RAM, 40GB Hard Drive) \\n Requested Attribute: Processor Speed\",\n",
        "#         \"attribute\": \"1.5GHz\"\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "examples = [\n",
        "   {\n",
        "        \"product_title\": \"Sony KV-20FV12 20 Trinitron Wega Flat-Screen TV \\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Screen Form', which is Flat. So the answer Flat.\"\n",
        "    }, {\n",
        "        \"product_title\": \"Fender Villager 12-String Acoustic-Electric Guitar \\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Guitar Type', which is Acoustic-Electric. So the answer Acoustic-Electric.\"\n",
        "    }, {\n",
        "        \"product_title\": \"Remanufactured IBM ThinkPad T23 1.13 GHz Pentium III Notebook PC with 30 GB \\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Processor Brand', which is Pentium. So the answer Pentium.\"\n",
        "    }, {\n",
        "        \"product_title\": \"Taylor Guitars NS72-CE Grand Concert Acoustic Electric Classical Guitar \\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Ukulele Type', which is Concert. So the answer Concert.\"\n",
        "    }, {\n",
        "        \"product_title\": \"RCA LCDX3022W 30 LCD Flat Panel HD-Compatible TV \\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Display Type', which is LCD. So the answer LCD.\"\n",
        "    },{\n",
        "        \"product_title\": \" HP Pavilion ZT1195 Notebook (1.5GHz Intel Pentium IIII, 512MB RAM, 40GB Hard Drive) \\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"Let's think step by step. The requested attribute in the given product title is 'Processor Speed', which is 1.5GHz. So the answer 1.5GHz.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O1KnZQwTDDbP"
      },
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Examples for example selector**"
      ],
      "metadata": {
        "id": "PQfuNoGbjtSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"product_title\": \"Compaq Presario 725US Notebook (Athlon-4 1600+, 256 MB RAM, 20 GB hard drive) \\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Athlon\"\n",
        "    },{\n",
        "        \"product_title\": \"Toshiba Satellite Pro M15-S405 Laptop (1.40-GHz Pentium-M(Centrino), 512 MB RAM, 40GB Hard Drive, DVD/CD-RW Drive) \\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Pentium\"\n",
        "    },{\n",
        "        \"product_title\": \" HP Pavilion ZE1230 Notebook Computer (AMD Athlon XP 1500+ processor, 256 MB RAM, 20 GB Hard Drive)\\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Athlon\"\n",
        "    },{\n",
        "        \"product_title\": \" Compaq Presario 700Z Notebook (1-GHz Athlon, 320 MB RAM, 15 GB hard drive)\\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Athlon\"\n",
        "    },{\n",
        "        \"product_title\": \" Hewlett-Packard Pavilion zt1170 Notebook (1.13-GHz Pentium III, 512 MB RAM, 30 GB hard drive)\\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Pentium\"\n",
        "    },{\n",
        "        \"product_title\": \" Sony VAIO PCG-R505GL Laptop (1.2 GHz Pentium III-M, 256 MB SDRAM, 30 GB hard drive\\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Pentium\"\n",
        "    },{\n",
        "        \"product_title\": \"ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB - HDD 20 GB - DVD - Savage/IX - Win2000 Pro - 14.1\\\" TFT 1024 x 768 ( XGA ) - black \\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"I do not know.\"\n",
        "    },{\n",
        "        \"product_title\": \"Sony VAIO PCG-FXA63 Laptop (1.4 GHz Athlon XP 1600+, 256 MB SDRAM, 20 GB hard drive \\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Athlon\"\n",
        "    },{\n",
        "        \"product_title\": \"Toshiba Satellite 5205-S505 Laptop (2.20-GHz Pentium 4-M, 512 MB RAM, 60 GB Hard Drive) \\n Requested Attribute: Processor Brand\",\n",
        "        \"attribute\": \"Pentium\"\n",
        "    },{\n",
        "        \"product_title\": \" Toshiba Satellite 1405-S151 Laptop (1.2-GHz Celeron, 256 MB RAM, 30 GB hard drive)\\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"1.2-GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" HP Pavilion ZT1195 Notebook (1.5GHz Intel Pentium IIII, 512MB RAM, 40GB Hard Drive) \\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"1.5GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" Sony VAIO PCG-GRX-550 Notebook Computer (1.6 GHz Intem Pentium IIII, 512 MB RAM, 30 GB Hard Drive)\\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"1.6 GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" Sony VAIO PCG-GRV680 Laptop (2.60-GHz Pentium 4, 512 MB RAM, 60 GB Hard Drive)\\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"2.60-GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" Sony VAIO PCG-GRX570 Laptop (1.6-GHz Pentium 4, 512 MB RAM, 40 GB hard drive) \\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"1.6-GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" Compaq Presario 915US Laptop (1.53 GHz Athlon XP 1800+ M, 256MB RAM, 40GB hard drive\\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"1.53 GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" ThinkPad T40 2373 - Pentium M 1.5 GHz - 14.1 \\\" - 512 MB Ram - 40 GB HDD\\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"1.5 GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" IBM ThinkPad R40 (27232FU) Laptop (1.30-GHz Pentium-M (Centrino), 256 MB RAM, 20 GB Hard Drive, DVD-ROM Drive)\\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"1.30-GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" Sony VAIO PCG-GRX-550 Notebook Computer (1.6 GHz Intem Pentium IIII, 512 MB RAM, 30 GB Hard Drive)\\n Requested Attribute: Processor Speed\",\n",
        "        \"attribute\": \"1.6 GHz\"\n",
        "    },{\n",
        "        \"product_title\": \" Panasonic PT40LC12 40\\\" 16:9 Widescreen Projection LCD Display\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"I do not know.\"\n",
        "    },{\n",
        "        \"product_title\": \" Sampo LME-17S3 17-Inch LCD Flat-Panel TV\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" SONY KLV-30XBR900 30\\\" LCD WEGA Flat Panel Television\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" Sharp Aquos LC-20B1U 20-Inch Flat-Panel LCD TV\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" Toshiba 50HP82 50-Inch Plasma Flat-Panel HD-Ready TV\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" Sharp Aquos LC-30HV4U 30-Inch LCD Flat-Panel HD-Ready TV\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" Magnavox 15MF200V 15-Inch LCD Flat-Panel Stereo TV\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" Samsung LTM-1775W 17-Inch LCD Flat-Panel HDTV-Ready TV\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" Sharp Aquos LC-22SV6U 22-Inch Flat-Panel LCD TV\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" Philips 32FD9954 32-Inch Plasma Flat-Panel TV\\n Requested Attribute: Screen Form\",\n",
        "        \"attribute\": \"Flat\"\n",
        "    },{\n",
        "        \"product_title\": \" Zenith P50W26B 50-Inch Plasma Flat-Panel HDTV\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"Plasma\"\n",
        "    },{\n",
        "        \"product_title\": \" Sharp LC-20E1U 20-Inch AQUOS LCD Flat-Panel TV, Silver\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"LCD\"\n",
        "    },{\n",
        "        \"product_title\": \" ViewSonic VPW425 42\\\" Plasma Flat-Panel HD-Ready TV\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"Plasma\"\n",
        "    },{\n",
        "        \"product_title\": \" Tatung V17AFTW 17-Inch LCD Flat-Panel TV\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"LCD\"\n",
        "    },{\n",
        "        \"product_title\": \" Zenith D36D51 36-Inch HDTV\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"I do not know.\"\n",
        "    },{\n",
        "        \"product_title\": \" Toshiba 36AF42 36\\\" Pure Flat Screen TV\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"I do not know.\"\n",
        "    },{\n",
        "        \"product_title\": \" Sony KV-27FS120 27-Inch FD Trinitron WEGA Flat Screen TV\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"I do not know.\"\n",
        "    },{\n",
        "        \"product_title\": \" Toshiba 32A41 32\\\" TV\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"I do not know.\"\n",
        "    },{\n",
        "        \"product_title\": \" Sharp Aquos LC-20B2UB 20-Inch Flat-Panel LCD TV , Black\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"LCD\"\n",
        "    },{\n",
        "        \"product_title\": \" Panasonic TC-17LA1 17\\\" LCD Flat-Panel EDTV TV (Silver)\\n Requested Attribute: Display Type\",\n",
        "        \"attribute\": \"LCD\"\n",
        "    },{\n",
        "        \"product_title\": \" Yamaha FS700S Solid Top Concert Acoustic Guitar Sand Burst\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"Acoustic\"\n",
        "    },{\n",
        "        \"product_title\": \" Fender 0284001106 Starcaster with Planet Waves/GO-DPS 16 Pick Sampler \\u2013 High-Gloss Black\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"I do not know.\"\n",
        "    },{\n",
        "        \"product_title\": \" Breedlove Discovery Concert CE Acoustic-Electric Guitar\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"Acoustic-Electric\"\n",
        "    },{\n",
        "        \"product_title\": \" Guild GAD M-120 Concert Size Acoustic Guitar - Natural with Case\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"Acoustic\"\n",
        "    },{\n",
        "        \"product_title\": \" Westwood WWCG39 Full-size Classical Guitar with Bag and Strap\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"Classical\"\n",
        "    },{\n",
        "        \"product_title\": \" Dean E09M Edge Mahogany Electric Bass Guitar - Natural\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"Electric Bass\"\n",
        "    },{\n",
        "        \"product_title\": \" Danelectro '56 Baritone Electric Guitar Red\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"I do not know.\"\n",
        "    },{\n",
        "        \"product_title\": \" Dean Edge 09 Bass Guitar, Classic Black\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"Bass\"\n",
        "    },{\n",
        "        \"product_title\": \" Montana CL40 3/4 Classical Guitar\\n Requested Attribute: Guitar Type\",\n",
        "        \"attribute\": \"Classical\"\n",
        "    },{\n",
        "        \"product_title\": \" Kala KA-SB Solid Spruce Top Baritone Ukulele\\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Baritone\"\n",
        "    },{\n",
        "        \"product_title\": \" Eastwood Warren Ellis Tenor - Cherry Red\\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Tenor\"\n",
        "    },{\n",
        "        \"product_title\": \" Honsing New Basswood Soprano Ukulele Hawaii Guitar 21\\\" Gift - Colored Petals\\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Soprano\"\n",
        "    },{\n",
        "        \"product_title\": \" Luna Maluhia Peace Concert Acoustic/Electric Ukulele with Preamp & Gig Bag, Satin Natural\\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Concert\"\n",
        "    },{\n",
        "        \"product_title\": \" Blueridge BR-40T Contemporary Series Tenor Guitar\\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Tenor\"\n",
        "    },{\n",
        "        \"product_title\": \" Blueridge BR-60T Contemporary Series Tenor Guitar with Hardshell Case\\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Tenor\"\n",
        "    },{\n",
        "        \"product_title\": \" Luna Guitars UKE-TEC-MAH-KIT-1 Tattoo Concert Electric Ukulele\\n Requested Attribute: Ukulele Type\",\n",
        "        \"attribute\": \"Concert\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "ogIZcg1zMXBA"
      },
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***One and few shot LLM chains***"
      ],
      "metadata": {
        "id": "6u4NiVAJCwKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "example_template = \"\"\"\n",
        "User: {product_title}\n",
        "{attribute}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "        template=example_template,\n",
        "        input_variables=[\"product_title\", \"attribute\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "cHJL6IW2fcfl"
      },
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Prompt**"
      ],
      "metadata": {
        "id": "OjA69Nw5j4MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"Extract the exact attribute value of the requested attribute from the following product title. Return the answer only. If the attribute value is not contained, respond with 'I do not know'.\\n Here are some examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "product_title: {input_string}\n",
        "attribute: \"\"\""
      ],
      "metadata": {
        "id": "g8G7AHJ_8x78"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt with Role**"
      ],
      "metadata": {
        "id": "xmuukVnBkD6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"I want you to act as a product catalog manager in a leading e-commerce company. Extract the exact attribute value of the requested attribute from the following product title. Return the answer only. If the attribute value is not contained, respond with 'I do not know'.\\n Here are some examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "product_title: {input_string}\n",
        "attribute: \"\"\""
      ],
      "metadata": {
        "id": "1Dc3xyE4T11k"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt with additional context**"
      ],
      "metadata": {
        "id": "e9YAqc4LkHkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"Extract the exact attribute value of the requested attribute from the following product title. Return the answer only. If the attribute value is not contained, respond with 'I do not know'.\\n\n",
        "The product titles are from three different categories 'Guitars', 'Laptops', and 'Television'.\\n\n",
        "'Guitars' category mainly have two attributes 'Guitar type' and 'Ukelele type'. Guitars are categorized by their construction, strings, and playing style, offering a diverse range from acoustic and electric to classical and bass. Ukuleles are categorized by their size, with soprano, concert, tenor, and baritone being the main sizes, each offering distinct tones and playability.\\n\n",
        "'Laptops' category mainly have two attributes 'Processor Speed' and 'Processor Brand'. Processor speeds for laptops can vary depending on the specific model and generation of the processor. The processor speed is typically measured in gigahertz (GHz). Some examples of processor brand are 'Athlon', 'Pentium', 'Intel', and 'AMD'.\\n\n",
        "'Television' category mainly have two attributes 'Display Type' and 'Screen Form'. The screen form of televisions is primarily categorized into flat screens and curved screens while the display types of televisions are categorized based on the underlying technology, with options such as LCD, LED, OLED, QLED, and MicroLED.\\n\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "product_title: {input_string}\n",
        "attribute: \"\"\""
      ],
      "metadata": {
        "id": "inor80EQy8WR"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt for Chain of thought**"
      ],
      "metadata": {
        "id": "XovPS0KNkLib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"What is the exact value of the Requested Attribute from the following product title? Respond by returning the answer only and nothing else. If the attribute value is not contained, respond with 'I do not know'.\\n\n",
        "Here are some examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "product_title: {input_string}\n",
        "attribute: \"\"\""
      ],
      "metadata": {
        "id": "z2TfOSkj4ODR"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate\n",
        "\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=['input_string'],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "8C0h-4VooT4I"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LangChain PromptTemplate\n",
        "from langchain import PromptTemplate, LLMChain, OpenAI\n",
        "\n",
        "gpt_3_turbo = OpenAI(model_name='gpt-3.5-turbo', openai_api_key = OPENAI_API_KEY)\n",
        "# gpt_3 = OpenAI(model_name='text-davinci-003', openai_api_key = OPENAI_API_KEY)\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=few_shot_prompt_template,\n",
        "    llm=gpt_3_turbo\n",
        ")\n",
        "\n",
        "targets = [example['target_scores'] for example in task_dict['examples']]\n",
        "with get_openai_callback() as cb:\n",
        "    preds = [llm_chain.run({'input_string': example['input']}) for example in task_dict['examples']]\n",
        "    print(f'Spent a total of {cb.total_tokens} tokens')"
      ],
      "metadata": {
        "id": "w03zLgsqfcOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19367a23-6a65-4670-845c-b714c5756c85"
      },
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 12510 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***NGram example selector***"
      ],
      "metadata": {
        "id": "6gNOfRAtr5YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts.example_selector.ngram_overlap import NGramOverlapExampleSelector"
      ],
      "metadata": {
        "id": "Z4mln68DN2mY"
      },
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_example_selector = NGramOverlapExampleSelector(\n",
        "    # These are the examples it has available to choose from.\n",
        "    examples=examples,\n",
        "    # This is the PromptTemplate being used to format the examples.\n",
        "    example_prompt=example_prompt,\n",
        "    # This is the threshold, at which selector stops.\n",
        "    # It is set to -1.0 by default.\n",
        "    threshold=0.17,\n",
        "    # For negative threshold:\n",
        "    # Selector sorts examples by ngram overlap score, and excludes none.\n",
        "    # For threshold greater than 1.0:\n",
        "    # Selector excludes all examples, and returns an empty list.\n",
        "    # For threshold equal to 0.0:\n",
        "    # Selector sorts examples by ngram overlap score,\n",
        "    # and excludes those with no ngram overlap with input.\n",
        ")"
      ],
      "metadata": {
        "id": "8o28xAHkR__z"
      },
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_dynamic_prompt = FewShotPromptTemplate(\n",
        "    # We provide an ExampleSelector instead of examples.\n",
        "    example_selector=ngram_example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=['input_string'],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "bDr5CQxOSD-0"
      },
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LangChain PromptTemplate\n",
        "from langchain import PromptTemplate, LLMChain, OpenAI\n",
        "\n",
        "# gpt_3_turbo = OpenAI(model_name='gpt-3.5-turbo', openai_api_key = OPENAI_API_KEY)\n",
        "gpt_3 = OpenAI(model_name='text-davinci-003', openai_api_key = OPENAI_API_KEY)\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=ngram_dynamic_prompt,\n",
        "    llm=gpt_3\n",
        ")\n",
        "\n",
        "targets = [example['target_scores'] for example in task_dict['examples']]\n",
        "with get_openai_callback() as cb:\n",
        "    preds = [llm_chain.run({'input_string': example['input']}) for example in task_dict['examples']]\n",
        "    print(f'Spent a total of {cb.total_tokens} tokens')"
      ],
      "metadata": {
        "id": "8UnoHZvjSTl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592222e0-120c-46cb-e234-981ddcc8c1f3"
      },
      "execution_count": 583,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 10805 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Semantic Simlarity example selector**"
      ],
      "metadata": {
        "id": "Rz5reidFrn2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "8C09oXPPbY8F"
      },
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key = OPENAI_API_KEY)\n",
        "\n",
        "sim_example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    # This is the list of examples available to select from.\n",
        "    examples,\n",
        "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
        "    embeddings,\n",
        "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
        "    Chroma,\n",
        "    # This is the number of examples to produce.\n",
        "    k=10\n",
        ")"
      ],
      "metadata": {
        "id": "xkZvyA3_bY5K"
      },
      "execution_count": 548,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate\n",
        "similar_dynamic_prompt = FewShotPromptTemplate(\n",
        "    example_selector=sim_example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=['input_string'],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "6XkIrniNbY2O"
      },
      "execution_count": 553,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LangChain PromptTemplate\n",
        "from langchain import PromptTemplate, LLMChain, OpenAI\n",
        "\n",
        "gpt_3_turbo = OpenAI(model_name='gpt-3.5-turbo', openai_api_key = OPENAI_API_KEY)\n",
        "# gpt_3 = OpenAI(model_name='text-davinci-003', openai_api_key = OPENAI_API_KEY)\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=similar_dynamic_prompt,\n",
        "    llm=gpt_3_turbo\n",
        ")\n",
        "\n",
        "targets = [example['target_scores'] for example in task_dict['examples']]\n",
        "with get_openai_callback() as cb:\n",
        "    preds = [llm_chain.run({'input_string': example['input']}) for example in task_dict['examples']]\n",
        "    print(f'Spent a total of {cb.total_tokens} tokens')"
      ],
      "metadata": {
        "id": "c0DGy2ZUcUGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0bf2f01-52fc-421d-8808-a4097af1dfef"
      },
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 9084 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***MMR Example Selector***"
      ],
      "metadata": {
        "id": "CAalrRLUqrTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector import MaxMarginalRelevanceExampleSelector\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "x5at88AI4Vnd"
      },
      "execution_count": 563,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmr_example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
        "    # This is the list of examples available to select from.\n",
        "    examples,\n",
        "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
        "    OpenAIEmbeddings(openai_api_key = OPENAI_API_KEY),\n",
        "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
        "    FAISS,\n",
        "    # This is the number of examples to produce.\n",
        "    k=10\n",
        ")"
      ],
      "metadata": {
        "id": "ugXD9Lty4Vqy"
      },
      "execution_count": 565,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmr_prompt = FewShotPromptTemplate(\n",
        "    # We provide an ExampleSelector instead of examples.\n",
        "    example_selector=mmr_example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"input_string\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "RFH2IGbk4Vtj"
      },
      "execution_count": 566,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LangChain PromptTemplate\n",
        "from langchain import PromptTemplate, LLMChain, OpenAI\n",
        "\n",
        "# gpt_3_turbo = OpenAI(model_name='gpt-3.5-turbo', openai_api_key = OPENAI_API_KEY)\n",
        "gpt_3 = OpenAI(model_name='text-davinci-003', openai_api_key = OPENAI_API_KEY)\n",
        "llm_chain = LLMChain(\n",
        "    prompt=mmr_prompt,\n",
        "    llm=gpt_3\n",
        ")\n",
        "\n",
        "targets = [example['target_scores'] for example in task_dict['examples']]\n",
        "with get_openai_callback() as cb:\n",
        "    preds = [llm_chain.run({'input_string': example['input']}) for example in task_dict['examples']]\n",
        "    print(f'Spent a total of {cb.total_tokens} tokens')"
      ],
      "metadata": {
        "id": "eFspJF6UgN3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd7d155-6741-49f3-bdda-07988fab080d"
      },
      "execution_count": 577,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 12726 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making Predictions**"
      ],
      "metadata": {
        "id": "gCwK7hGMkYxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [pred.replace('\\n','') for pred in preds]\n",
        "preds = [pred.strip() for pred in preds]\n",
        "preds = [pred.replace('Answer: ','') for pred in preds]\n",
        "preds"
      ],
      "metadata": {
        "id": "UV1TjIWg5sMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Printing Results***"
      ],
      "metadata": {
        "id": "yb9UyV7nrTvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def calculate_recall_precision_f1(targets, preds, categories, attributes):\n",
        "    unique_attributes = list(set(attributes))\n",
        "    unique_categories = list(set(categories))\n",
        "\n",
        "    result_dict = {}\n",
        "\n",
        "    for unique_category in unique_categories:\n",
        "        for unique_attribute in unique_attributes:\n",
        "\n",
        "            eval_nn = 0 # the model can predict No value (I do not know.) when ground truth is No attribute value\n",
        "            eval_nv = 0 # some incorrect Value when ground truth is No attribute value\n",
        "            eval_vn = 0 # the model can predict No value (I do not know.) when the ground truth has attribute Values\n",
        "            eval_vc = 0 # Correct values when the ground truth has attribute Values\n",
        "            eval_vw = 0 # Wrong values when the ground truth has attribute Values\n",
        "\n",
        "            for target, pred, category, attribute in zip(targets, preds, categories, attributes):\n",
        "                if unique_attribute != attribute or unique_category != category:\n",
        "                    # Evaluate per attribute/category\n",
        "                    continue\n",
        "\n",
        "                target_values = [value if value != \"I do not know.\" else None for value in target]\n",
        "                prediction = pred if pred != \"I do not know.\" else None\n",
        "\n",
        "                #print(target_values)\n",
        "                #print(prediction)\n",
        "\n",
        "                if target_values[0] is None and prediction is None:\n",
        "                    eval_nn += 1\n",
        "                elif target_values[0] is None and prediction is not None:\n",
        "                    eval_nv += 1\n",
        "                elif target_values[0] is not None and prediction is None:\n",
        "                    eval_vn += 1\n",
        "                elif prediction in target_values:\n",
        "                    eval_vc += 1\n",
        "                else:\n",
        "                    eval_vw += 1\n",
        "\n",
        "            precision = round((eval_vc / (eval_nv + eval_vc + eval_vw))*100, 2) if (eval_nv + eval_vc + eval_vw) > 0 else 0\n",
        "            recall = round((eval_vc / (eval_vn + eval_vc + eval_vw))*100, 2) if (eval_vn + eval_vc + eval_vw) > 0 else 0\n",
        "            f1 = round(2* precision* recall/ (precision + recall), 2) if (precision + recall) > 0 else 0\n",
        "\n",
        "            if (eval_nv + eval_vc + eval_vw) == 0 and (eval_vn + eval_vc + eval_vw) == 0:\n",
        "                # Combination does not exist\n",
        "                continue\n",
        "\n",
        "            result_dict['{}_{}'.format(unique_attribute, unique_category)] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "            print('Attribute: {} - Category: {}'.format(unique_attribute, unique_category))\n",
        "            print(result_dict['{}_{}'.format(unique_attribute, unique_category)])\n",
        "\n",
        "    #Calculate macro scores\n",
        "    precision_scores = [result_dict['{}_{}'.format(attribute, category)]['precision'] for attribute, category in product(unique_attributes, unique_categories)\n",
        "                        if '{}_{}'.format(attribute, category) in result_dict]\n",
        "    macro_precision = round(sum(precision_scores)/ len(precision_scores), 2)\n",
        "\n",
        "    recall_scores = [result_dict['{}_{}'.format(attribute, category)]['recall'] for attribute, category in product(unique_attributes, unique_categories)\n",
        "                        if '{}_{}'.format(attribute, category) in result_dict]\n",
        "    macro_recall = round(sum(recall_scores)/ len(recall_scores), 2)\n",
        "\n",
        "    f1_scores = [result_dict['{}_{}'.format(attribute, category)]['f1'] for attribute, category in product(unique_attributes, unique_categories)\n",
        "                        if '{}_{}'.format(attribute, category) in result_dict]\n",
        "    macro_f1 = round(sum(f1_scores)/ len(f1_scores), 2)\n",
        "\n",
        "\n",
        "    result_dict['macro'] = {'macro_precision': macro_precision, 'macro_recall': macro_recall, 'macro_f1': macro_f1}\n",
        "    print(result_dict['macro'])\n",
        "\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "z_iLGu3LEyZ1"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [example['target_scores'] for example in task_dict['examples']]\n",
        "\n",
        "categories = [example['category'] for example in task_dict['examples']]\n",
        "attributes = [example['attributes'] for example in task_dict['examples']]"
      ],
      "metadata": {
        "id": "vk70jN1IExx0"
      },
      "execution_count": 588,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = calculate_recall_precision_f1(targets, preds, categories, attributes)"
      ],
      "metadata": {
        "id": "LZrlOTd7V3ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Analysis\n",
        "print('Prompts for which target and postprocessed prediction do not match.')\n",
        "print('-----------')\n",
        "input_texts = [example['input'] for example in task_dict['examples']]\n",
        "for input_text, target, pred in zip(input_texts, targets, preds):\n",
        "    # print('Prompt: {}'.format(prompt.format(task_prefix= task_dict['task_prefix'], input_string= input_text)))\n",
        "    # print('Prompt: {}'.format(few_shot_prompt_template.format(input_string= input_text)))\n",
        "    print('Prompt: {}'.format(similar_dynamic_prompt.format(input_string= input_text)))\n",
        "    # print('Prompt: {}'.format(ngram_dynamic_prompt.format(input_string= input_text)))\n",
        "    # print('Prompt: {}'.format(mmr_prompt.format(input_string= input_text)))\n",
        "    #print('Task Prefix: {}'.format())\n",
        "    #print('Input Text: {}'.format(input_text))\n",
        "    print('Target: {}'.format(target))\n",
        "    print('Prediction: {}'.format(pred))\n",
        "    print('-----------')"
      ],
      "metadata": {
        "id": "HOYcvejNw5aE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
